<h2> Lectures (Tom Mitchell and Maria-Florina Balcan) </h2>

<table class="schedule" border="1" cellspacing="0">
<tbody>
<tr>
<th>Lecture</th>
<th>Topics</th>
<th>Readings and useful links</th>
<th>Handouts</th>
</tr>
<tr>
<td>Intro to ML<br />Decision Trees</td>
<td>
<ul>
<li>Machine learning examples</li>
<li>Well defined machine learning problem</li>
<li>Decision tree learning</li>
</ul>
</td>
<td>Mitchell: Ch 3<br />Bishop: Ch 14.4<br /><a href="MachineLearning.pdf" data-smd-id="s15">The Discipline of Machine Learning</a></td>
<td><a href="01_DTreesAndOverfitting-1-12-2015.pdf" data-smd-id="s16">Slides</a></td>
</tr>
<tr>
<td>Decision Tree learning<br />Review of Probability</td>
<td>
<ul>
<li>The big picture</li>
<li>Overfitting</li>
<li>Random variables and probabilities</li>
</ul>
</td>
<td>Mitchell: Ch 3<br /><a href="prob18.pdf" data-smd-id="s18">Andrew Moore's Basic Probability Tutorial</a></td>
<td><a href="02_Overfitting_ProbReview-1-14-2015.pdf" data-smd-id="s19">Slides</a><br /><a href="02_Overfitting_ProbReview-1-14-2015_ann.pdf" data-smd-id="s20">Annotated Slides</a></td>
</tr>
<tr>
<td>Probability and Estimation</td>
<td>
<ul>
<li>Bayes rule</li>
<li>MLE</li>
<li>MAP</li>
</ul>
</td>
<td>Mitchell:&nbsp;<a href="Joint_MLE_MAP.pdf" data-smd-id="s22">Estimating Probabilities</a></td>
<td><a href="03_MLE_MAP_NBayes-1-21-2015.pdf" data-smd-id="s23">Slides</a><br /><a href="03_MLE_MAP_NBayes-1-21-2015_ann.pdf" data-smd-id="s24">Annotated Slides</a></td>
</tr>
<tr>
<td>Naive Bayes</td>
<td>
<ul>
<li>Conditional Independence</li>
<li>Naive Bayes: why and how</li>
</ul>
</td>
<td>Mitchell:&nbsp;<a href="NBayesLogReg.pdf" data-smd-id="s26">Naive Bayes and Logistic Regression</a></td>
<td><a href="04_NBayes-1-26-2015.pptx.pdf" data-smd-id="s27">Slides</a><br /><a href="04_NBayes-1-26-2015-ann.pdf" data-smd-id="s28">Annotated Slides</a></td>
</tr>
<tr>
<td>Gaussian Naive Bayes</td>
<td>
<ul>
<li>Gaussian Bayes classifiers</li>
<li>Document Classification</li>
<li>Brain image classification</li>
<li>Form of decision surfaces</li>
</ul>
</td>
<td>Mitchell:&nbsp;<a href="NBayesLogReg.pdf" data-smd-id="s30">Naive Bayes and Logistic Regression</a></td>
<td><a href="05_GNB_1-28-2015.pdf" data-smd-id="s31">Slides</a><br /><a href="05_GNB_1-28-2015-ann.pdf" data-smd-id="s32">Annotated Slides</a></td>
</tr>
<tr>
<td>Logistic Regression</td>
<td>
<ul>
<li>Naive Bayes - the big picture</li>
<li>Logistic Regression: Maximizing conditional likelihood</li>
<li>Gradient ascent as a general learning/optimization method</li>
</ul>
</td>
<td>Mitchell:&nbsp;<a href="NBayesLogReg.pdf" data-smd-id="s34">Naive Bayes and Logistic Regression</a></td>
<td><a href="06_GenDiscr_LR_2-2-2015.pdf" data-smd-id="s35">Slides</a><br /><a href="06_GenDiscr_LR_2-2-2015-ann.pdf" data-smd-id="s36">Annotated Slides</a></td>
</tr>
<tr>
<td>Linear Regression</td>
<td>
<ul>
<li>Generative/Discriminative models</li>
<li>Minimizing squared error and maximizing data likelihood</li>
<li>Regularization</li>
<li>Bias-variance decomposition</li>
</ul>
</td>
<td>&nbsp;</td>
<td><a href="07_GenDiscr2_2-4-2015.pdf" data-smd-id="s38">Slides</a><br /><a href="07_GenDiscr2_2-4-2015-ann.pdf" data-smd-id="s39">Annotated Slides</a></td>
</tr>
<tr>
<td>Learning Theory I</td>
<td>
<ul>
<li>Distributional Learning</li>
<li>PAC and Statistical Learning Theory</li>
<li>Sample Complexity</li>
</ul>
</td>
<td>Mitchell: Ch 7<br /><a href="sc-2015.pdf" data-smd-id="s41">Notes on Generalization Guarantees</a></td>
<td><a href="08_Theory_2-9-2015.pdf" data-smd-id="s42">Slides</a></td>
</tr>
<tr>
<td>Learning Theory II</td>
<td>
<ul>
<li>Sample Complexity</li>
<li>Shattering and VC Dimension</li>
<li>Sauer's Lemma</li>
</ul>
</td>
<td>Mitchell: Ch 7<br /><a href="sc-2015.pdf" data-smd-id="s44">Notes on Generalization Guarantees</a></td>
<td><a href="09_Theory2_2-11-2015.pdf" data-smd-id="s45">Slides</a></td>
</tr>
<tr>
<td>Learning Theory III</td>
<td>
<ul>
<li>Rademacher Complexity</li>
<li>Overfitting and Regularization</li>
</ul>
</td>
<td>&nbsp;</td>
<td><a href="10_Theory3_2-16-2015.pdf" data-smd-id="s47">Slides</a></td>
</tr>
<tr>
<td>Graphical Models I</td>
<td>
<ul>
<li>Bayes Nets</li>
<li>Representing joint distributions with conditional independence assumptions</li>
</ul>
</td>
<td>Bishop chapter 8, through 8.2</td>
<td><a href="11_GrMod1_2-18-2015.pdf" data-smd-id="s49">Slides</a><br /><a href="11_GrMod1_2-18-2015-ann.pdf" data-smd-id="s50">Annotated Slides</a></td>
</tr>
<tr>
<td>Graphical Models II</td>
<td>
<ul>
<li>Inference</li>
<li>Learning from fully observed data</li>
<li>Learning from partially observed data</li>
</ul>
</td>
<td>&nbsp;</td>
<td><a href="12_GrMod1_2-23-2015-ann.pdf" data-smd-id="s52">Annotated Slides</a></td>
</tr>
<tr>
<td>Graphical Models III</td>
<td>
<ul>
<li>EM</li>
<li>Semi-supervised learning</li>
</ul>
</td>
<td>Bishop Chapter 8<br />Mitchell Chapter 6</td>
<td><a href="13_GrMod3_2-25-2015.pdf" data-smd-id="s54">Slides</a><br /><a href="13_GrMod3_2-25-2015-ann.pdf" data-smd-id="s55">Annotated Slides</a></td>
</tr>
<tr>
<td colspan="4"><strong>Exam #1</strong></td>
</tr>
<tr>
<td>EM and Clustering</td>
<td>
<ul>
<li>Mixture of Gaussian clustering</li>
<li>K-means clustering</li>
</ul>
</td>
<td>Bishop Chapter 8<br />Mitchell Chapter 6</td>
<td><a href="14_GrMod4_3-4-2015.pdf" data-smd-id="s57">Slides</a><br /><a href="14_GrMod4_3-4-2015-ann.pdf" data-smd-id="s58">Annotated Slides</a></td>
</tr>
<tr>
<td colspan="4">Spring Break</td>
</tr>
<tr>
<td>Boosting</td>
<td>
<ul>
<li>Weak vs Strong (PAC) Learning</li>
<li>Boosting Accuracy</li>
<li>Adaboost</li>
</ul>
</td>
<td>
<ul>
<li><a href="schapire02boosting_schapire.pdf" data-smd-id="s60">The Boosting Approach to Machine Learning: An Overview</a></li>
<li><a href="nips-tutorial.pdf" data-smd-id="s61">Theory and Applications of Boosting (NIPS Tutorial)</a></li>
</ul>
</td>
<td><a href="15_boosting_3-16-2015.pdf" data-smd-id="s62">Slides</a></td>
</tr>
<tr>
<td>Adaboost, Margins, Perceptron</td>
<td>
<ul>
<li>Adaboost: Generalization Guarantees(naive and margins based).</li>
<li>Geometric Margins and Perceptron</li>
</ul>
</td>
<td><a href="perceptron-notes.pdf" data-smd-id="s64">Notes on Perceptron</a></td>
<td><a href="16_boosting-percepton-margins_03-18-2015.pdf" data-smd-id="s65">Slides</a><br /><a href="16_boosting-percepton-margins_03-18-2015.pptx" data-smd-id="s66">Slides (PPT)</a></td>
</tr>
<tr>
<td>Kernels</td>
<td>
<ul>
<li>Geometric Margins</li>
<li>Kernels: Kernelizing a Learning Algorithm</li>
<li>Kernelized Perceptron</li>
</ul>
</td>
<td>Bishop 6.1 and 6.2</td>
<td><a href="17_margins-kernels_03-23-2015.pdf" data-smd-id="s68">Slides</a></td>
</tr>
<tr>
<td>SVM</td>
<td>
<ul>
<li>Geometric Margins</li>
<li>SVM: Primal and Dual Forms</li>
<li>Kernelizing SVM</li>
<li>Semi-supervised Learning</li>
<li>Semi-supervised SVM</li>
</ul>
</td>
<td><a href="cs229-notes3.pdf" data-smd-id="s70">Notes on SVM by Andrew Ng</a></td>
<td><a href="18_svm-ssl_03-25-2015.pdf" data-smd-id="s71">Slides</a></td>
</tr>
<tr>
<td>Semi-supervised Learning</td>
<td>
<ul>
<li>Transductive SVM</li>
<li>Co-training and Multi-view Learning</li>
<li>Graph-based Methods</li>
</ul>
</td>
<td>
<ul>
<li><a href="SSL_EoML.pdf" data-smd-id="s73">"Semi-Supervised Learning" in Encyclopedia of Machine Learning</a></li>
<li><a href="joachims_99c.pdf" data-smd-id="s75">Transductive SVM Paper</a></li>
</ul>
</td>
<td><a href="19_ssl_03-30-2015.pdf" data-smd-id="s76">Slides</a></td>
</tr>
<tr>
<td>Active Learning</td>
<td>
<ul>
<li>Batch Active Learning</li>
<li>Selective Sampling and Active Learning</li>
<li>Sampling Bias</li>
</ul>
</td>
<td>
<ul>
<li><a href="twoface.pdf" data-smd-id="s78">Two Faces of Active Learning</a></li>
<li><a href="settles.activelearning.pdf" data-smd-id="s79">Active Learning Literature Survey (by Burr Settles)</a></li>
<li><a href="al-survey-enc-algos.pdf" data-smd-id="s80">Active Learning Survey (by Balcan and Urner)</a></li>
</ul>
</td>
<td><a href="20_al_4-1-2015.pdf" data-smd-id="s81">Slides</a></td>
</tr>
<tr>
<td>
<ul>
<li>Partitional Clustering</li>
<li>Hierarchical Clustering</li>
</ul>
</td>
<td>
<ul>
<li>k-means, Lloyd's method, k-means++</li>
<li>Agglomerative Clustering</li>
</ul>
</td>
<td>
<ul>
<li>Hastie, Tibshirani and Friedman, Chapter 14.3</li>
<li><a href="cluster-chapter.pdf" data-smd-id="s83">Center Based Clustering: A Foundational Perspective</a></li>
</ul>
</td>
<td><a href="21_clustering_4-6-2015.pdf" data-smd-id="s84">Slides</a></td>
</tr>
<tr>
<td>
<ul>
<li>Learning Representations</li>
<li>Dimensionality Reduction</li>
</ul>
</td>
<td>
<ul>
<li>Principal Component Analysis</li>
<li>Kernel Principal Component Analysis</li>
</ul>
</td>
<td>
<ul>Bishop 12.1, 12.3</ul>
</td>
<td><a href="22_pca-04-09-2015.pdf" data-smd-id="s86">Slides</a></td>
</tr>
<tr>
<td>Never Ending Learning</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td><a href="23_nell_4-13-2015.pdf" data-smd-id="s88">Slides</a></td>
</tr>
<tr>
<td>Neural Networks<br />Deep Learning</td>
<td>&nbsp;</td>
<td>Mitchell, Chapter 4</td>
<td><a href="24_nn_4-15-2015.pdf" data-smd-id="s90">Slides</a></td>
</tr>
<tr>
<td>Reinforcement Learning</td>
<td>
<ul>
<li>Markov Decision Processes</li>
<li>Value Iteration</li>
<li>Q-learning</li>
</ul>
</td>
<td>
<ul>
<li>Mitchell, Chapter 13</li>
<li><a href="live-301-1562-jair.pdf" data-smd-id="s92">Kaelbling, et al., Reinforcement Learning: A Survey</a></li>
</ul>
</td>
<td><a href="25_rl_4-20-2015.pdf" data-smd-id="s93">Slides</a></td>
</tr>
<tr>
<td>Deep Learning<br />Differential Privacy<br />Discussion on the Future of ML</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td><a href="26_privacy_4-22-2015.pdf" data-smd-id="s95">Slides (Privacy)</a><br /><a href="26_deep_4-22-2015.pdf" data-smd-id="s96">Slides (Deep Nets)</a></td>
</tr>
</tbody>
</table>
</br>

<p><strong>Andrew Ng's review notes on:</strong></p>
<ul>
<li><a href="1/cs229-linalg.pdf" target="_blank" rel="nofollow">Linear Algebra</a></li>
<li><a href="1/cs229-prob.pdf" target="_blank" rel="nofollow">Probability Theory</a></li>
<li><a href="1/gaussians.pdf" target="_blank" rel="nofollow">Multivariate Gaussian - I</a></li>
<li><a href="1/more_on_gaussians.pdf" target="_blank" rel="nofollow">Multivariate Gaussian - II</a></li>
<li><a href="1/cs229-cvxopt.pdf" target="_blank" rel="nofollow">Convex Optimization - I</a></li>
<li><a href="1/cs229-cvxopt2.pdf" target="_blank" rel="nofollow">Convex Optimization - II</a></li>
<li><a href="1/cs229-hmm.pdf" target="_blank" rel="nofollow">Hidden Markov Models</a></li>  
  
</ul>
</br>
<h2> Lecture Notes </h2>
<ul>
<li>Andrew Ng's&nbsp;<a href="1/loss-functions.pdf" target="_blank" rel="nofollow">notes on Loss Functions</a></li>
<li>Andrew Ng's course notes on&nbsp;<a href="1/cs229-notes1.pdf" target="_blank" rel="nofollow">Linear and Logistic Regression</a>.</li>
<li><a href="1/1905.12787.pdf" target="_blank" rel="nofollow">The Theory Behind Overfitting, Cross Validation, Regularization, Bagging and Boosting: Tutorial</a>&nbsp;by Ghojogh and Crowley.</li>
<li>Andrew Ng's notes on&nbsp;<a href="1/cs229-notes2.pdf" target="_blank" rel="nofollow">Naive Bayes</a>&nbsp;</li>
<li>Andrew Ng's notes on&nbsp;<a href="1/cs229-notes3.pdf" target="_blank" rel="nofollow">SVM and Kernel Methods</a></li>
<li>Andrew Ng's notes on&nbsp;<a href="1/cs229-notes-deep_learning.pdf" target="_blank" rel="nofollow">Neural Networks and Deep Learning</a></li>
<li>[Practical Tips] -&nbsp;<a href="1/lecun-98b.pdf" target="_blank" rel="nofollow">Efficient Backprop</a>&nbsp;by Yann LeCun</li>
<li>Vapnik's paper on "<a href="1/506-principles-of-risk-minimization-for-learning-theory.pdf" target="_blank" rel="nofollow">Principles of Risk Minimization for Learning Theory</a>", NIPS 1992</li>
 <li>Andrew Ng's &nbsp;<a href="machine-learning-4.2.pdf" target="_blank" rel="nofollow">ML Review Notes</a>&nbsp;</li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(1).pdf" style="text-decoration:none;">Spectral Methods for
Dimensionality Reduction</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(2).pdf" style="text-decoration:none;">Nonlinear Dimensionality
Reduction by Locally Linear Embedding</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(3).pdf" style="text-decoration:none;">MATLAB Workshop 2: An introduction to Support Vector Machine implementations in MATLAB</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(4).pdf" style="text-decoration:none;">Neighbourhood Components Analysis</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(5).pdf" style="text-decoration:none;">A Global Geometric Framework
for Nonlinear Dimensionality Reduction</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(6).pdf" style="text-decoration:none;">Graphics Principles Cheat Sheet</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(7).pdf" style="text-decoration:none;">Neural Machine Translation and Sequence-to-sequence Models: A Tutorial</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(8).pdf" style="text-decoration:none;"> Exponential Families </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(9).pdf" style="text-decoration:none;">Variational Inference: A Review for Statisticians</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(10).pdf" style="text-decoration:none;">Foundations of Data Science </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(11).pdf" style="text-decoration:none;">Optimization Methods for Large-Scale Machine Learning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(12).pdf" style="text-decoration:none;">Convex Optimization</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(13).pdf" style="text-decoration:none;">Theoretical Computer Science Cheat Sheet</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(14).pdf" style="text-decoration:none;">Entropy, Relative Entropy, And Mutual Information</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(15).pdf" style="text-decoration:none;">Information Theory
And Statistics</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(16).pdf" style="text-decoration:none;">Lecture #7: Understanding and Using Principal
Component Analysis (PCA)</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(17).pdf" style="text-decoration:none;">
Lecture #9: The Singular Value Decomposition (SVD) and Low-Rank Matrix Approximations</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(18).pdf" style="text-decoration:none;">CS224n: Natural Language Processing with Deep
Learning (Lecture Notes: Part I)</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(19).pdf" style="text-decoration:none;">Super VIP Cheatsheet: Machine Learning</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(20).pdf" style="text-decoration:none;">
CSE176 Introduction to Machine Learning â€” Lecture notes</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(21).pdf" style="text-decoration:none;">Linear Algebra Review and Reference</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(22).pdf" style="text-decoration:none;">Lecture notes (Roger Grosse)</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(23).pdf" style="text-decoration:none;">Data Mining, Inference, and Prediction</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(24).pdf" style="text-decoration:none;">A Primer on Neural Network Models
for Natural Language Processing</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(25).pdf" style="text-decoration:none;">Machine Learning and Data Mining
Lecture Notes</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(26).pdf" style="text-decoration:none;">Common tests are linear models</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(27).pdf" style="text-decoration:none;">
Linear Algebra Abridged</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(28).pdf" style="text-decoration:none;">The Matrix Calculus You Need For Deep Learning</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(29).pdf" style="text-decoration:none;">Measure, Integration
and Real Analysis</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(30).pdf" style="text-decoration:none;">Concise Machine Learning</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(31).pdf" style="text-decoration:none;">Machine Learning Basic Concepts</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(32).pdf" style="text-decoration:none;">
Notation: Overview</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(33).pdf" style="text-decoration:none;">Lecture Notes 1: Vector spaces</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(34).pdf" style="text-decoration:none;">Probability Cheatsheet</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(35).pdf" style="text-decoration:none;">An overview of gradient descent optimization
algorithms</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(36).pdf" style="text-decoration:none;">Lecture 0: Course Introduction</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(37).pdf" style="text-decoration:none;">A Structural Approach to Selection Bias</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(38).pdf" style="text-decoration:none;">Troubleshooting Deep Neural Networks: A Field Guide to Fixing Your Model</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(39).pdf" style="text-decoration:none;">Introduction to
Applied Linear Algebra</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(40).pdf" style="text-decoration:none;">Python For Data Science Cheat Sheet (NumPy Basics)</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(41).pdf" style="text-decoration:none;">Data Wrangling with pandas Cheat Sheet</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(42).pdf" style="text-decoration:none;">Python For Data Science Cheat Sheet
(Scikit-Learn)</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(43).pdf" style="text-decoration:none;">Python For Data Science Cheat Sheet
(Keras)</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(44).pdf" style="text-decoration:none;">Data Wrangling with dplyr and tidyr Cheat Sheet</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(45).pdf" style="text-decoration:none;">Data Visualization with ggplot2
Cheat Sheet</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/ML-Lectures/blob/master/ml(46).pdf" style="text-decoration:none;">CS725 : Foundations of Machine learning - Lecture Notes</a></li> 
                             
 
 
 
 
</ul>

</br>


<h3>C19 ML lectures [Andrew Zisserman]</h3>
<ul>
<li>
<p><a href="1/lect1.pdf">Lecture 1 "Introduction"</a></p>
</li>
<li>
<p><a href="1/lect2.pdf">Lecture 2 "The SVM Classifier"</a></p>
</li>
<li>
<p><a href="1/lect3.pdf">Lecture 3 "SVM dual, kernels and regression"</a></p>
</li>
<li>
<p><a href="1/lect4.pdf">Lecture 4 "Regression continued and multiple classes"</a></p>
</li>
<li><a href="1/examples.pdf">Examples sheet</a></li>
</ul>






