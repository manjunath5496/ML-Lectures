<h2> Lectures (Tom Mitchell and Maria-Florina Balcan) </h2>

<table class="schedule" border="1" cellspacing="0">
<tbody>
<tr>
<th>Lecture</th>
<th>Topics</th>
<th>Readings and useful links</th>
<th>Handouts</th>
</tr>
<tr>
<td>Intro to ML<br />Decision Trees</td>
<td>
<ul>
<li>Machine learning examples</li>
<li>Well defined machine learning problem</li>
<li>Decision tree learning</li>
</ul>
</td>
<td>Mitchell: Ch 3<br />Bishop: Ch 14.4<br /><a href="MachineLearning.pdf" data-smd-id="s15">The Discipline of Machine Learning</a></td>
<td><a href="01_DTreesAndOverfitting-1-12-2015.pdf" data-smd-id="s16">Slides</a></td>
</tr>
<tr>
<td>Decision Tree learning<br />Review of Probability</td>
<td>
<ul>
<li>The big picture</li>
<li>Overfitting</li>
<li>Random variables and probabilities</li>
</ul>
</td>
<td>Mitchell: Ch 3<br /><a href="prob18.pdf" data-smd-id="s18">Andrew Moore's Basic Probability Tutorial</a></td>
<td><a href="02_Overfitting_ProbReview-1-14-2015.pdf" data-smd-id="s19">Slides</a><br /><a href="02_Overfitting_ProbReview-1-14-2015_ann.pdf" data-smd-id="s20">Annotated Slides</a></td>
</tr>
<tr>
<td>Probability and Estimation</td>
<td>
<ul>
<li>Bayes rule</li>
<li>MLE</li>
<li>MAP</li>
</ul>
</td>
<td>Mitchell:&nbsp;<a href="Joint_MLE_MAP.pdf" data-smd-id="s22">Estimating Probabilities</a></td>
<td><a href="03_MLE_MAP_NBayes-1-21-2015.pdf" data-smd-id="s23">Slides</a><br /><a href="03_MLE_MAP_NBayes-1-21-2015_ann.pdf" data-smd-id="s24">Annotated Slides</a></td>
</tr>
<tr>
<td>Naive Bayes</td>
<td>
<ul>
<li>Conditional Independence</li>
<li>Naive Bayes: why and how</li>
</ul>
</td>
<td>Mitchell:&nbsp;<a href="NBayesLogReg.pdf" data-smd-id="s26">Naive Bayes and Logistic Regression</a></td>
<td><a href="04_NBayes-1-26-2015.pptx.pdf" data-smd-id="s27">Slides</a><br /><a href="04_NBayes-1-26-2015-ann.pdf" data-smd-id="s28">Annotated Slides</a></td>
</tr>
<tr>
<td>Gaussian Naive Bayes</td>
<td>
<ul>
<li>Gaussian Bayes classifiers</li>
<li>Document Classification</li>
<li>Brain image classification</li>
<li>Form of decision surfaces</li>
</ul>
</td>
<td>Mitchell:&nbsp;<a href="NBayesLogReg.pdf" data-smd-id="s30">Naive Bayes and Logistic Regression</a></td>
<td><a href="05_GNB_1-28-2015.pdf" data-smd-id="s31">Slides</a><br /><a href="05_GNB_1-28-2015-ann.pdf" data-smd-id="s32">Annotated Slides</a></td>
</tr>
<tr>
<td>Logistic Regression</td>
<td>
<ul>
<li>Naive Bayes - the big picture</li>
<li>Logistic Regression: Maximizing conditional likelihood</li>
<li>Gradient ascent as a general learning/optimization method</li>
</ul>
</td>
<td>Mitchell:&nbsp;<a href="NBayesLogReg.pdf" data-smd-id="s34">Naive Bayes and Logistic Regression</a></td>
<td><a href="06_GenDiscr_LR_2-2-2015.pdf" data-smd-id="s35">Slides</a><br /><a href="06_GenDiscr_LR_2-2-2015-ann.pdf" data-smd-id="s36">Annotated Slides</a></td>
</tr>
<tr>
<td>Linear Regression</td>
<td>
<ul>
<li>Generative/Discriminative models</li>
<li>Minimizing squared error and maximizing data likelihood</li>
<li>Regularization</li>
<li>Bias-variance decomposition</li>
</ul>
</td>
<td>&nbsp;</td>
<td><a href="07_GenDiscr2_2-4-2015.pdf" data-smd-id="s38">Slides</a><br /><a href="07_GenDiscr2_2-4-2015-ann.pdf" data-smd-id="s39">Annotated Slides</a></td>
</tr>
<tr>
<td>Learning Theory I</td>
<td>
<ul>
<li>Distributional Learning</li>
<li>PAC and Statistical Learning Theory</li>
<li>Sample Complexity</li>
</ul>
</td>
<td>Mitchell: Ch 7<br /><a href="sc-2015.pdf" data-smd-id="s41">Notes on Generalization Guarantees</a></td>
<td><a href="08_Theory_2-9-2015.pdf" data-smd-id="s42">Slides</a></td>
</tr>
<tr>
<td>Learning Theory II</td>
<td>
<ul>
<li>Sample Complexity</li>
<li>Shattering and VC Dimension</li>
<li>Sauer's Lemma</li>
</ul>
</td>
<td>Mitchell: Ch 7<br /><a href="sc-2015.pdf" data-smd-id="s44">Notes on Generalization Guarantees</a></td>
<td><a href="09_Theory2_2-11-2015.pdf" data-smd-id="s45">Slides</a></td>
</tr>
<tr>
<td>Learning Theory III</td>
<td>
<ul>
<li>Rademacher Complexity</li>
<li>Overfitting and Regularization</li>
</ul>
</td>
<td>&nbsp;</td>
<td><a href="10_Theory3_2-16-2015.pdf" data-smd-id="s47">Slides</a></td>
</tr>
<tr>
<td>Graphical Models I</td>
<td>
<ul>
<li>Bayes Nets</li>
<li>Representing joint distributions with conditional independence assumptions</li>
</ul>
</td>
<td>Bishop chapter 8, through 8.2</td>
<td><a href="11_GrMod1_2-18-2015.pdf" data-smd-id="s49">Slides</a><br /><a href="11_GrMod1_2-18-2015-ann.pdf" data-smd-id="s50">Annotated Slides</a></td>
</tr>
<tr>
<td>Graphical Models II</td>
<td>
<ul>
<li>Inference</li>
<li>Learning from fully observed data</li>
<li>Learning from partially observed data</li>
</ul>
</td>
<td>&nbsp;</td>
<td><a href="12_GrMod1_2-23-2015-ann.pdf" data-smd-id="s52">Annotated Slides</a></td>
</tr>
<tr>
<td>Graphical Models III</td>
<td>
<ul>
<li>EM</li>
<li>Semi-supervised learning</li>
</ul>
</td>
<td>Bishop Chapter 8<br />Mitchell Chapter 6</td>
<td><a href="13_GrMod3_2-25-2015.pdf" data-smd-id="s54">Slides</a><br /><a href="13_GrMod3_2-25-2015-ann.pdf" data-smd-id="s55">Annotated Slides</a></td>
</tr>
<tr>
<td colspan="4"><strong>Exam #1</strong></td>
</tr>
<tr>
<td>EM and Clustering</td>
<td>
<ul>
<li>Mixture of Gaussian clustering</li>
<li>K-means clustering</li>
</ul>
</td>
<td>Bishop Chapter 8<br />Mitchell Chapter 6</td>
<td><a href="14_GrMod4_3-4-2015.pdf" data-smd-id="s57">Slides</a><br /><a href="14_GrMod4_3-4-2015-ann.pdf" data-smd-id="s58">Annotated Slides</a></td>
</tr>
<tr>
<td colspan="4">Spring Break</td>
</tr>
<tr>
<td>Boosting</td>
<td>
<ul>
<li>Weak vs Strong (PAC) Learning</li>
<li>Boosting Accuracy</li>
<li>Adaboost</li>
</ul>
</td>
<td>
<ul>
<li><a href="schapire02boosting_schapire.pdf" data-smd-id="s60">The Boosting Approach to Machine Learning: An Overview</a></li>
<li><a href="nips-tutorial.pdf" data-smd-id="s61">Theory and Applications of Boosting (NIPS Tutorial)</a></li>
</ul>
</td>
<td><a href="15_boosting_3-16-2015.pdf" data-smd-id="s62">Slides</a></td>
</tr>
<tr>
<td>Adaboost, Margins, Perceptron</td>
<td>
<ul>
<li>Adaboost: Generalization Guarantees(naive and margins based).</li>
<li>Geometric Margins and Perceptron</li>
</ul>
</td>
<td><a href="perceptron-notes.pdf" data-smd-id="s64">Notes on Perceptron</a></td>
<td><a href="16_boosting-percepton-margins_03-18-2015.pdf" data-smd-id="s65">Slides</a><br /><a href="16_boosting-percepton-margins_03-18-2015.pptx" data-smd-id="s66">Slides (PPT)</a></td>
</tr>
<tr>
<td>Kernels</td>
<td>
<ul>
<li>Geometric Margins</li>
<li>Kernels: Kernelizing a Learning Algorithm</li>
<li>Kernelized Perceptron</li>
</ul>
</td>
<td>Bishop 6.1 and 6.2</td>
<td><a href="17_margins-kernels_03-23-2015.pdf" data-smd-id="s68">Slides</a></td>
</tr>
<tr>
<td>SVM</td>
<td>
<ul>
<li>Geometric Margins</li>
<li>SVM: Primal and Dual Forms</li>
<li>Kernelizing SVM</li>
<li>Semi-supervised Learning</li>
<li>Semi-supervised SVM</li>
</ul>
</td>
<td><a href="cs229-notes3.pdf" data-smd-id="s70">Notes on SVM by Andrew Ng</a></td>
<td><a href="18_svm-ssl_03-25-2015.pdf" data-smd-id="s71">Slides</a></td>
</tr>
<tr>
<td>Semi-supervised Learning</td>
<td>
<ul>
<li>Transductive SVM</li>
<li>Co-training and Multi-view Learning</li>
<li>Graph-based Methods</li>
</ul>
</td>
<td>
<ul>
<li><a href="SSL_EoML.pdf" data-smd-id="s73">"Semi-Supervised Learning" in Encyclopedia of Machine Learning</a></li>
<li><a href="joachims_99c.pdf" data-smd-id="s75">Transductive SVM Paper</a></li>
</ul>
</td>
<td><a href="19_ssl_03-30-2015.pdf" data-smd-id="s76">Slides</a></td>
</tr>
<tr>
<td>Active Learning</td>
<td>
<ul>
<li>Batch Active Learning</li>
<li>Selective Sampling and Active Learning</li>
<li>Sampling Bias</li>
</ul>
</td>
<td>
<ul>
<li><a href="twoface.pdf" data-smd-id="s78">Two Faces of Active Learning</a></li>
<li><a href="settles.activelearning.pdf" data-smd-id="s79">Active Learning Literature Survey (by Burr Settles)</a></li>
<li><a href="al-survey-enc-algos.pdf" data-smd-id="s80">Active Learning Survey (by Balcan and Urner)</a></li>
</ul>
</td>
<td><a href="20_al_4-1-2015.pdf" data-smd-id="s81">Slides</a></td>
</tr>
<tr>
<td>
<ul>
<li>Partitional Clustering</li>
<li>Hierarchical Clustering</li>
</ul>
</td>
<td>
<ul>
<li>k-means, Lloyd's method, k-means++</li>
<li>Agglomerative Clustering</li>
</ul>
</td>
<td>
<ul>
<li>Hastie, Tibshirani and Friedman, Chapter 14.3</li>
<li><a href="cluster-chapter.pdf" data-smd-id="s83">Center Based Clustering: A Foundational Perspective</a></li>
</ul>
</td>
<td><a href="21_clustering_4-6-2015.pdf" data-smd-id="s84">Slides</a></td>
</tr>
<tr>
<td>
<ul>
<li>Learning Representations</li>
<li>Dimensionality Reduction</li>
</ul>
</td>
<td>
<ul>
<li>Principal Component Analysis</li>
<li>Kernel Principal Component Analysis</li>
</ul>
</td>
<td>
<ul>Bishop 12.1, 12.3</ul>
</td>
<td><a href="22_pca-04-09-2015.pdf" data-smd-id="s86">Slides</a></td>
</tr>
<tr>
<td>Never Ending Learning</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td><a href="23_nell_4-13-2015.pdf" data-smd-id="s88">Slides</a></td>
</tr>
<tr>
<td>Neural Networks<br />Deep Learning</td>
<td>&nbsp;</td>
<td>Mitchell, Chapter 4</td>
<td><a href="24_nn_4-15-2015.pdf" data-smd-id="s90">Slides</a></td>
</tr>
<tr>
<td>Reinforcement Learning</td>
<td>
<ul>
<li>Markov Decision Processes</li>
<li>Value Iteration</li>
<li>Q-learning</li>
</ul>
</td>
<td>
<ul>
<li>Mitchell, Chapter 13</li>
<li><a href="live-301-1562-jair.pdf" data-smd-id="s92">Kaelbling, et al., Reinforcement Learning: A Survey</a></li>
</ul>
</td>
<td><a href="25_rl_4-20-2015.pdf" data-smd-id="s93">Slides</a></td>
</tr>
<tr>
<td>Deep Learning<br />Differential Privacy<br />Discussion on the Future of ML</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td><a href="26_privacy_4-22-2015.pdf" data-smd-id="s95">Slides (Privacy)</a><br /><a href="26_deep_4-22-2015.pdf" data-smd-id="s96">Slides (Deep Nets)</a></td>
</tr>
</tbody>
</table>
</br>

<p><strong>Andrew Ng's review notes on:</strong></p>
<ul>
<li><a href="1/cs229-linalg.pdf" target="_blank" rel="nofollow">Linear Algebra</a></li>
<li><a href="1/cs229-prob.pdf" target="_blank" rel="nofollow">Probability Theory</a></li>
<li><a href="1/gaussians.pdf" target="_blank" rel="nofollow">Multivariate Gaussian - I</a></li>
<li><a href="1/more_on_gaussians.pdf" target="_blank" rel="nofollow">Multivariate Gaussian - II</a></li>
<li><a href="1/cs229-cvxopt.pdf" target="_blank" rel="nofollow">Convex Optimization - I</a></li>
<li><a href="1/cs229-cvxopt2.pdf" target="_blank" rel="nofollow">Convex Optimization - II</a></li>
</ul>
</br>



